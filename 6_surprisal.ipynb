{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from model import *\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from train import *\n",
    "\n",
    "# Check if GPU is available\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_multi_torch(y_true, y_pred, dim=0):\n",
    "    \"\"\"\n",
    "    Compute correlation between y_true and y_pred per target dimension.\n",
    "    Inputs: (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    y_true_z = zscore_tensor(y_true, dim=dim)\n",
    "    y_pred_z = zscore_tensor(y_pred, dim=dim)\n",
    "\n",
    "    return torch.mean(y_true_z * y_pred_z, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_list = dict(\n",
    "    Moth1=[\"souls\", \"avatar\", \"legacy\", \"odetostepfather\"],\n",
    "    Moth2=[\"howtodraw\", \"myfirstdaywiththeyankees\", \"naked\", \"life\"],\n",
    "    Moth3=[\"tildeath\", \"fromboyhoodtofatherhood\", \"sloth\", \"exorcism\"],\n",
    "    Moth4=[\"adollshouse\", \"inamoment\", \"theclosetthatateeverything\", \"adventuresinsayingyes\", \"haveyoumethimyet\"],\n",
    "    Moth5=[\"thatthingonmyarm\", \"eyespy\", \"itsabox\", \"hangtime\"],\n",
    ")\n",
    "train_stories = [story for session in train_story_list.keys() for story in train_story_list[session]]\n",
    "val_stories = [[\"swimmingwithastronauts1\", \"swimmingwithastronauts2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alternateithicatom1',\n",
       " 'souls',\n",
       " 'wheretheressmoke1',\n",
       " 'avatar',\n",
       " 'legacy',\n",
       " 'odetostepfather',\n",
       " 'undertheinfluence1',\n",
       " 'howtodraw',\n",
       " 'myfirstdaywiththeyankees',\n",
       " 'naked',\n",
       " 'life',\n",
       " 'stagefright1',\n",
       " 'tildeath',\n",
       " 'fromboyhoodtofatherhood',\n",
       " 'sloth',\n",
       " 'exorcism',\n",
       " 'buck1',\n",
       " 'adollshouse',\n",
       " 'inamoment',\n",
       " 'theclosetthatateeverything',\n",
       " 'adventuresinsayingyes',\n",
       " 'haveyoumethimyet',\n",
       " 'swimmingwithastronauts1',\n",
       " 'thatthingonmyarm',\n",
       " 'eyespy',\n",
       " 'itsabox',\n",
       " 'hangtime']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let test stories be all 27 stories\n",
    "with open(\"data/story_to_uniquestory.pkl\", \"rb\") as f:\n",
    "    story_to_uniquestory = pickle.load(f)\n",
    "test_stories = list(story_to_uniquestory.keys())\n",
    "test_stories = [s for s in test_stories if s != \"stimuli_auditory_localizer\" and not s[-1] in [\"2\", \"3\", \"4\", \"5\"]]\n",
    "test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "name = \"WdPnFq-seg8-flexconv4-A\"\n",
    "which = \"val-loss-min\"\n",
    "SAVEFIG = False\n",
    "\n",
    "with open(f\"config/{name}.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "MEG_SUBJECT = config[\"MEG_SUBJECT\"]\n",
    "FMRI_SUBJECT = config[\"FMRI_SUBJECT\"]\n",
    "use_segment = config[\"use_segment\"]\n",
    "spacing = config[\"spacing\"]\n",
    "meg_loss_weight = config[\"meg_loss_weight\"]\n",
    "fmri_loss_weight = config[\"fmri_loss_weight\"]\n",
    "softmax_T = config[\"softmax_T\"]\n",
    "dataset_params = config[\"dataset\"]\n",
    "model_params = config[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_word: True, use_phoneme: True, use_freq: True, use_meg: False, use_mri: False\n",
      "embed_dim:  852\n",
      "use_word: True, use_phoneme: True, use_freq: True, use_meg: False, use_mri: False\n",
      "embed_dim:  852\n",
      "Loading story swimmingwithastronauts1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading story swimmingwithastronauts1!\n",
      "Loading story swimmingwithastronauts2...\n",
      "Finished loading story swimmingwithastronauts2!\n",
      "Preloaded all stories!\n",
      "use_word: True, use_phoneme: True, use_freq: True, use_meg: False, use_mri: False\n",
      "embed_dim:  852\n",
      "Loading story alternateithicatom1...\n",
      "Finished loading story alternateithicatom1!\n",
      "Loading story souls...\n",
      "Finished loading story souls!\n",
      "Loading story wheretheressmoke1...\n",
      "Finished loading story wheretheressmoke1!\n",
      "Loading story avatar...\n",
      "Finished loading story avatar!\n",
      "Loading story legacy...\n",
      "Finished loading story legacy!\n",
      "Loading story odetostepfather...\n",
      "Finished loading story odetostepfather!\n",
      "Loading story undertheinfluence1...\n",
      "Finished loading story undertheinfluence1!\n",
      "Loading story howtodraw...\n",
      "Finished loading story howtodraw!\n",
      "Loading story myfirstdaywiththeyankees...\n",
      "Finished loading story myfirstdaywiththeyankees!\n",
      "Loading story naked...\n",
      "Finished loading story naked!\n",
      "Loading story life...\n",
      "Finished loading story life!\n",
      "Loading story stagefright1...\n",
      "Finished loading story stagefright1!\n",
      "Loading story tildeath...\n",
      "Finished loading story tildeath!\n",
      "Loading story fromboyhoodtofatherhood...\n",
      "Finished loading story fromboyhoodtofatherhood!\n",
      "Loading story sloth...\n",
      "Finished loading story sloth!\n",
      "Loading story exorcism...\n",
      "Finished loading story exorcism!\n",
      "Loading story buck1...\n",
      "Finished loading story buck1!\n",
      "Loading story adollshouse...\n",
      "Finished loading story adollshouse!\n",
      "Loading story inamoment...\n",
      "Finished loading story inamoment!\n",
      "Loading story theclosetthatateeverything...\n",
      "Finished loading story theclosetthatateeverything!\n",
      "Loading story adventuresinsayingyes...\n",
      "Finished loading story adventuresinsayingyes!\n",
      "Loading story haveyoumethimyet...\n",
      "Finished loading story haveyoumethimyet!\n",
      "Loading story swimmingwithastronauts1...\n",
      "Finished loading story swimmingwithastronauts1!\n",
      "Loading story thatthingonmyarm...\n",
      "Finished loading story thatthingonmyarm!\n",
      "Loading story eyespy...\n",
      "Finished loading story eyespy!\n",
      "Loading story itsabox...\n",
      "Finished loading story itsabox!\n",
      "Loading story hangtime...\n",
      "Finished loading story hangtime!\n",
      "Preloaded all stories!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = StoryDataset(\n",
    "    MEG_SUBJECT,\n",
    "    FMRI_SUBJECT,\n",
    "    train_stories[0:1],\n",
    "    name=name,\n",
    "    spacing=spacing,\n",
    "    preload=False,\n",
    "    **dataset_params,\n",
    ")  # evalulate don't care this\n",
    "val_dataset = StoryDataset(\n",
    "    MEG_SUBJECT,\n",
    "    FMRI_SUBJECT,\n",
    "    val_stories,\n",
    "    name=name,\n",
    "    spacing=spacing,\n",
    "    pca_meg=train_dataset.pca_meg,\n",
    "    pca_mri=train_dataset.pca_mri,\n",
    "    **dataset_params,\n",
    ")\n",
    "test_dataset = StoryDataset(\n",
    "    MEG_SUBJECT,\n",
    "    FMRI_SUBJECT,\n",
    "    test_stories,\n",
    "    name=name,\n",
    "    spacing=spacing,\n",
    "    pca_meg=train_dataset.pca_meg,\n",
    "    pca_mri=train_dataset.pca_mri,\n",
    "    MEG_DIR=\"moth_meg\",\n",
    "    **dataset_params,\n",
    ")\n",
    "embed_dim = test_dataset.embed_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading forward solution from /home/yishuli/MEG-fMRI/data/A-oct6-fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523 (FIFF_MNE_FORWARD_SOLUTION_GRAD)) not available\n",
      "    Read MEG forward solution (8196 sources, 306 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(306, 8196)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load forward solution to get the lead field\n",
    "fname_fwd = f\"data/{MEG_SUBJECT}-{spacing}-fwd.fif\"\n",
    "fwd = mne.read_forward_solution(fname_fwd)\n",
    "fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True, use_cps=True)  # let's do fixed orientation\n",
    "lead_field = fwd_fixed[\"sol\"][\"data\"]\n",
    "lead_field = torch.from_numpy(lead_field)\n",
    "n_channels, n_neurons = lead_field.shape\n",
    "n_channels, n_neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 1.0055146501442056, 0.07546357089945342, 0.9299632706765684)\n"
     ]
    }
   ],
   "source": [
    "model = TransformerSourceModel(\n",
    "    embed_dim=embed_dim,\n",
    "    lead_field=lead_field,\n",
    "    **model_params,\n",
    ").to(device)\n",
    "ckpt_path = f\"trained_models/{name}_{which}.pth\"\n",
    "info = load_checkpoint(ckpt_path, model, None, None, device=device)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_meg_loss: 0.07466866387896606, val_fmri_loss: 0.9308459862652395\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    validate(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "        subject=MEG_SUBJECT,\n",
    "        meg_loss_weight=meg_loss_weight,\n",
    "        fmri_loss_weight=fmri_loss_weight,\n",
    "        softmax_T=softmax_T,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "neurons_dict, neurons_power_dict = {}, {}\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    # load data\n",
    "    embeds, _, _ = test_dataset[i]\n",
    "    embeds = embeds.to(device)\n",
    "    # foward pass\n",
    "    with torch.no_grad():\n",
    "        neurons, _, _ = model(embeds.unsqueeze(0))\n",
    "        neurons = neurons.squeeze(0).detach().cpu()\n",
    "        # calculate power\n",
    "        neurons_power = hilbert_torch(neurons, dim=0)\n",
    "        neurons_power = neurons_power.abs()\n",
    "        neurons_power.pow_(2)\n",
    "        # zscore\n",
    "        neurons = zscore_tensor(torch.abs(neurons), dim=0).numpy()\n",
    "        neurons_power = zscore_tensor(neurons_power, dim=0).numpy()\n",
    "    neurons_dict[test_stories[i]] = neurons\n",
    "    neurons_power_dict[test_stories[i]] = neurons_power\n",
    "    # save memory\n",
    "    del embeds\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid transcript\n",
    "with open(\"data/moth_word_surprisal_context20.pkl\", \"rb\") as fp:\n",
    "    story_word_surprisal_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_surprisals = []\n",
    "for story in story_word_surprisal_dict.keys():\n",
    "    story_word_surprisal = story_word_surprisal_dict[story]\n",
    "    all_surprisals.extend([t[-2] for t in story_word_surprisal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram of the surprisal\n",
    "plt.hist(all_surprisals, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Word Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading textgrids\n",
    "words = dict()\n",
    "word_onset = dict()\n",
    "word_surprisal = dict()\n",
    "DEFAULT_BAD_WORDS = [\"sentence_start\", \"sentence_end\", \"{SL}\", \"{{BR}\", \"{BR}\", \"(BR}\", \"{BR\", \"{LG}\", \"{ls}\", \"{LS}\", \"{IG}\", \"{CG}\", \"{LS)\", \"{NS}\", \"{NS_AP}\", \"{SP}\", \"sp\", \"\", \" \"]\n",
    "content_pos = [\"NOUN\"]\n",
    "\n",
    "for this_story in test_stories:\n",
    "    this_story_unique = story_to_uniquestory[this_story]\n",
    "    story_word_surprisal = story_word_surprisal_dict[this_story_unique]\n",
    "    # correct delay\n",
    "    time_features = [tuple([float(t[0]), float(t[1])] + list(t[2:])) for t in story_word_surprisal]\n",
    "    time_features_corrected = get_stretched_features(time_features, MEG_SUBJECT, None, None, use_mean_rate=True)\n",
    "    words_this_story, word_onset_this_story, word_surprisal_this_story = [], [], []\n",
    "    for t in time_features_corrected:\n",
    "        if t[2] in DEFAULT_BAD_WORDS or t[-1] not in content_pos:\n",
    "            continue\n",
    "        else:\n",
    "            word_onset_this_story.append(float(t[0]))\n",
    "            words_this_story.append(t[2])\n",
    "            word_surprisal_this_story.append(float(t[-2]))\n",
    "    words[this_story] = words_this_story\n",
    "    word_onset[this_story] = np.array(word_onset_this_story)\n",
    "    word_surprisal[this_story] = np.array(word_surprisal_this_story)\n",
    "\n",
    "del story_word_surprisal_dict, story_word_surprisal, time_features, time_features_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lags\n",
    "sfreq = 50\n",
    "step = int(1000 / sfreq)  # 20ms\n",
    "lag_sample_start = -10\n",
    "lag_sample_end = 50\n",
    "lag_samples = np.arange(lag_sample_start, lag_sample_end + 1)\n",
    "lags = lag_samples * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get neuron response for each word onset\n",
    "neurons_onset, neurons_power_onset = [], []\n",
    "surprisals = []\n",
    "for story in test_stories:\n",
    "    word_onset_story = word_onset[story]\n",
    "    word_surprisal_story = word_surprisal[story]\n",
    "    neurons_story = neurons_dict[story]\n",
    "    neurons_power_story = neurons_power_dict[story]\n",
    "    for t, s in zip(word_onset_story, word_surprisal_story):\n",
    "        t_sample = int(t * 50)\n",
    "        t_sample_start = t_sample + lag_sample_start\n",
    "        t_sample_end = t_sample + lag_sample_end + 1\n",
    "        if t_sample_start > 0 and t_sample_end < neurons_power_story.shape[0]:\n",
    "            neurons_onset.append(neurons_story[t_sample_start:t_sample_end, :])\n",
    "            neurons_power_onset.append(neurons_power_story[t_sample_start:t_sample_end, :])\n",
    "            surprisals.append(s)\n",
    "neurons_onset = np.stack(neurons_onset)\n",
    "neurons_power_onset = np.stack(neurons_power_onset)\n",
    "surprisals = np.array(surprisals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13627, 61, 8196), (13627, 61, 8196), (13627,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_onset.shape, neurons_power_onset.shape, surprisals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del neurons_dict, neurons_power_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate surprisal with neuron response\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "neurons_onset_corrs = np.zeros((neurons_onset.shape[1], neurons_onset.shape[2]))\n",
    "neurons_onset_ps = np.zeros((neurons_onset.shape[1], neurons_onset.shape[2]))\n",
    "neurons_power_onset_corrs = np.zeros((neurons_power_onset.shape[1], neurons_power_onset.shape[2]))\n",
    "neurons_power_onset_ps = np.zeros((neurons_power_onset.shape[1], neurons_power_onset.shape[2]))\n",
    "\n",
    "for i in range(neurons_onset.shape[1]):\n",
    "    for j in range(neurons_onset.shape[2]):\n",
    "        corr, p = pearsonr(neurons_onset[:, i, j], surprisals)\n",
    "        neurons_onset_corrs[i, j] = corr\n",
    "        neurons_onset_ps[i, j] = p\n",
    "        corr_power, p_power = pearsonr(neurons_power_onset[:, i, j], surprisals)\n",
    "        neurons_power_onset_corrs[i, j] = corr_power\n",
    "        neurons_power_onset_ps[i, j] = p_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_thresh = 1e-50\n",
    "neurons_onset_ps_corrected = fdr_correction(neurons_onset_ps, alpha=p_thresh, method=\"bh\")[1]\n",
    "\n",
    "# thresh corr\n",
    "neurons_onset_corrs_thresh = neurons_onset_corrs.copy()\n",
    "neurons_onset_corrs_thresh[neurons_onset_ps_corrected > p_thresh] = 0\n",
    "\n",
    "# thresh p\n",
    "neurons_onset_ps_corrected[neurons_onset_ps_corrected > p_thresh] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meg_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
